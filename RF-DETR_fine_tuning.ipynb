{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec16545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능: True\n",
      "GPU 개수: 1\n",
      "현재 GPU: 0\n",
      "GPU 이름: NVIDIA H100 80GB HBM3\n",
      "GPU 메모리: 79.2 GB\n",
      "CUDA 환경 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "# CUDA 환경 초기화 및 메모리 정리\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "from rfdetr import RFDETRBase\n",
    "# CUDA 캐시 정리\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "    print(f\"GPU 개수: {torch.cuda.device_count()}\")\n",
    "    print(f\"현재 GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU 이름: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# 파이썬 메모리 정리\n",
    "gc.collect()\n",
    "# CUDA 디버깅 환경 설정\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print(\"CUDA 환경 초기화 완료\")\n",
    "device=torch.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e6ca79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Train 데이터:\n",
      "  - 이미지 수: 2570\n",
      "  - 어노테이션 수: 536130\n",
      "  - 카테고리 수: 3\n",
      "    - pd-l1 negative tumor cell (ID: 1): 169874개\n",
      "    - pd-l1 positive tumor cell (ID: 2): 54297개\n",
      "    - non-tumor cell (ID: 3): 311959개\n",
      "✓ 모든 category_id가 유효합니다\n",
      "\n",
      "✓ 데이터셋 검증 완료. 모델 초기화를 진행합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_classes mismatch: pretrain weights has 90 classes, but your model has 3 classes\n",
      "reinitializing detection head with 90 classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n",
      "✓ 모델 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 검증 먼저 수행\n",
    "\n",
    "\n",
    "# 데이터 경로 설정\n",
    "data_path = '../../data/coco_IGNITE/'\n",
    "result_path = '../../results/TPS_RFDETR/'\n",
    "model_path = '../../model/TPS_RFDETR/'\n",
    "\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# COCO 데이터셋 유효성 검사\n",
    "def validate_coco_dataset(data_path):\n",
    "    try:\n",
    "        # train 데이터 확인\n",
    "        with open(os.path.join(data_path, 'train/_annotations.coco.json'), 'r') as f:\n",
    "            train_data = json.load(f)\n",
    "        \n",
    "        print(f\"✓ Train 데이터:\")\n",
    "        print(f\"  - 이미지 수: {len(train_data['images'])}\")\n",
    "        print(f\"  - 어노테이션 수: {len(train_data['annotations'])}\")\n",
    "        print(f\"  - 카테고리 수: {len(train_data['categories'])}\")\n",
    "        \n",
    "        # 카테고리 정보 출력\n",
    "        for cat in train_data['categories']:\n",
    "            cat_count = len([ann for ann in train_data['annotations'] if ann['category_id'] == cat['id']])\n",
    "            print(f\"    - {cat['name']} (ID: {cat['id']}): {cat_count}개\")\n",
    "        \n",
    "        # 유효한 category_id 범위 확인\n",
    "        valid_cat_ids = [cat['id'] for cat in train_data['categories']]\n",
    "        ann_cat_ids = [ann['category_id'] for ann in train_data['annotations']]\n",
    "        invalid_ids = [cid for cid in ann_cat_ids if cid not in valid_cat_ids]\n",
    "        \n",
    "        if invalid_ids:\n",
    "            print(f\"⚠️ 잘못된 category_id 발견: {set(invalid_ids)}\")\n",
    "            return False\n",
    "        else:\n",
    "            print(\"✓ 모든 category_id가 유효합니다\")\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터셋 검증 실패: {e}\")\n",
    "        return False\n",
    "\n",
    "# 데이터셋 검증 실행\n",
    "if validate_coco_dataset(data_path):\n",
    "    print(\"\\n✓ 데이터셋 검증 완료. 모델 초기화를 진행합니다...\")\n",
    "    \n",
    "    # 모델 초기화 (클래스 수 명시적 설정)\n",
    "    model = RFDETRBase(\n",
    "        num_classes=3,  # pd-l1 negative(1), pd-l1 positive(2), non-tumor(3)\n",
    "        device='cuda'\n",
    "    )\n",
    "    \n",
    "    print(\"✓ 모델 초기화 완료\")\n",
    "else:\n",
    "    print(\"❌ 데이터셋에 문제가 있습니다. COCO 데이터 생성을 다시 확인해주세요.\")\n",
    "model=model.model.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c504249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LWDETR(\n",
       "  (transformer): Transformer(\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn): MSDeformAttn(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout2): Dropout(p=0, inplace=False)\n",
       "          (dropout3): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (ref_point_head): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc_output): ModuleList(\n",
       "      (0-12): 13 x Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (enc_output_norm): ModuleList(\n",
       "      (0-12): 13 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_out_bbox_embed): ModuleList(\n",
       "      (0-12): 13 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc_out_class_embed): ModuleList(\n",
       "      (0-12): 13 x Linear(in_features=256, out_features=91, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bbox_embed): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (refpoint_embed): Embedding(3900, 4)\n",
       "  (query_feat): Embedding(3900, 256)\n",
       "  (backbone): Joiner(\n",
       "    (0): Backbone(\n",
       "      (encoder): DinoV2(\n",
       "        (encoder): WindowedDinov2WithRegistersBackbone(\n",
       "          (embeddings): WindowedDinov2WithRegistersEmbeddings(\n",
       "            (patch_embeddings): Dinov2WithRegistersPatchEmbeddings(\n",
       "              (projection): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (encoder): WindowedDinov2WithRegistersEncoder(\n",
       "            (layer): ModuleList(\n",
       "              (0-11): 12 x WindowedDinov2WithRegistersLayer(\n",
       "                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "                (attention): Dinov2WithRegistersSdpaAttention(\n",
       "                  (attention): Dinov2WithRegistersSdpaSelfAttention(\n",
       "                    (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                    (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                    (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): Dinov2WithRegistersSelfOutput(\n",
       "                    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (layer_scale1): Dinov2WithRegistersLayerScale()\n",
       "                (drop_path): Identity()\n",
       "                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): Dinov2WithRegistersMLP(\n",
       "                  (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (activation): GELUActivation()\n",
       "                  (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                )\n",
       "                (layer_scale2): Dinov2WithRegistersLayerScale()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (layernorm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (projector): MultiScaleProjector(\n",
       "        (stages_sampling): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0-3): 4 x Sequential()\n",
       "          )\n",
       "        )\n",
       "        (stages): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): C2f(\n",
       "              (cv1): ConvX(\n",
       "                (conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNorm()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): ConvX(\n",
       "                (conv): Conv2d(640, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNorm()\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (m): ModuleList(\n",
       "                (0-2): 3 x Bottleneck(\n",
       "                  (cv1): ConvX(\n",
       "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn): LayerNorm()\n",
       "                    (act): SiLU(inplace=True)\n",
       "                  )\n",
       "                  (cv2): ConvX(\n",
       "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                    (bn): LayerNorm()\n",
       "                    (act): SiLU(inplace=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PositionEmbeddingSine()\n",
       "  )\n",
       "  (class_embed): Linear(in_features=256, out_features=91, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f1cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
